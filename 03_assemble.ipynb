{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Step 3: Assemble Context\n",
        "\n",
        "This notebook sets up vector search and assembles all the context needed for contract classification.\n",
        "\n",
        "**What it does:**\n",
        "1. Creates a `sections` table by splitting each document into its section headers and text\n",
        "2. Sets up Databricks Vector Search indexes on the `flat`, `doc_info`, and `sections` tables\n",
        "3. Assembles a comprehensive context table that combines -- for each contract -- its own info, folder-level related documents, and semantically similar documents found via vector search\n",
        "\n",
        "The assembled table is what gets fed to the LLM in Step 4 (Classify). It gives the model everything it needs to determine whether a contract is a master agreement, identify amendments, and figure out final expiry dates.\n",
        "\n",
        "**Before you run this:**\n",
        "- Steps 1 and 2 must be complete\n",
        "- The `flat`, `references`, and `doc_info` tables must exist with data\n",
        "- You need a Vector Search endpoint (the notebook will create one if it doesn't exist)\n",
        "\n",
        "**Output tables:**\n",
        "- `sections` -- document text split by section header\n",
        "- `assembled` -- full context per contract (own info + folder docs + vector search results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dbutils.widgets.text(\"catalog\", \"shm\", \"Catalog\")\n",
        "dbutils.widgets.text(\"schema\", \"contract\", \"Schema\")\n",
        "dbutils.widgets.text(\"endpoint_name\", \"contract_vs\", \"Vector Search Endpoint\")\n",
        "dbutils.widgets.text(\"parsed_table\", \"parsed\", \"Parsed Table Name\")\n",
        "dbutils.widgets.text(\"vs_char_limit\", \"8000\", \"Vector Search Character Limit\")\n",
        "\n",
        "catalog = dbutils.widgets.get(\"catalog\")\n",
        "schema = dbutils.widgets.get(\"schema\")\n",
        "endpoint_name = dbutils.widgets.get(\"endpoint_name\")\n",
        "parsed_table = dbutils.widgets.get(\"parsed_table\")\n",
        "vs_char_limit = dbutils.widgets.get(\"vs_char_limit\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install databricks-vectorsearch\n",
        "%restart_python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from databricks.vector_search.client import VectorSearchClient\n",
        "client = VectorSearchClient()\n",
        "\n",
        "catalog = dbutils.widgets.get(\"catalog\")\n",
        "schema = dbutils.widgets.get(\"schema\")\n",
        "endpoint_name = dbutils.widgets.get(\"endpoint_name\")\n",
        "parsed_table = dbutils.widgets.get(\"parsed_table\")\n",
        "vs_char_limit = dbutils.widgets.get(\"vs_char_limit\")\n",
        "\n",
        "# Tables we want to index for vector search\n",
        "tables = {\n",
        "  \"flat\": {\n",
        "    'columns_to_sync': ['path', 'vendor_name', 'file_name', 'vendor_folder_paths', 'preamble'],\n",
        "    'vs_col': 'preamble'\n",
        "  },\n",
        "  \"doc_info\": {\n",
        "    'columns_to_sync': ['path', 'combined_doc_info'],\n",
        "    'vs_col': 'combined_doc_info'\n",
        "  }, \n",
        "  \"sections\": {\n",
        "    'columns_to_sync': ['path', 'section_id', 'section_title', 'combined_text'],\n",
        "    'vs_col': 'combined_text'\n",
        "  }\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 3A: Create Sections Table\n",
        "\n",
        "This splits each parsed document into sections based on section headers. Each row is one section of one document, with the section title and combined text. This is mainly useful for agentic flows where the agent can search specific sections."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "sql"
        }
      },
      "outputs": [],
      "source": [
        "CREATE TABLE IF NOT EXISTS IDENTIFIER(:catalog || '.' || :schema || '.sections') (\n",
        "    path STRING,\n",
        "    section_id INT,\n",
        "    section_title STRING,\n",
        "    text STRING,\n",
        "    combined_text STRING\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "sql"
        }
      },
      "outputs": [],
      "source": [
        "MERGE INTO IDENTIFIER(:catalog || '.' || :schema || '.sections') AS target\n",
        "USING (\n",
        "  WITH exploded_elements AS (\n",
        "    SELECT\n",
        "      p.path,\n",
        "      element:id::STRING AS element_id,\n",
        "      element:type::STRING AS element_type,\n",
        "      element:content::STRING AS element_content\n",
        "    FROM (SELECT * FROM IDENTIFIER(:catalog || '.' || :schema || '.' || :parsed_table)) AS p,\n",
        "    LATERAL explode(cast(p.parsed:document:elements AS ARRAY<VARIANT>)) AS t(element)\n",
        "    WHERE element:id IS NOT NULL\n",
        "  ),\n",
        "  section_headers AS (\n",
        "    SELECT\n",
        "      path,\n",
        "      element_id,\n",
        "      element_content,\n",
        "      ROW_NUMBER() OVER (PARTITION BY path ORDER BY element_id::INT) AS mono_section_id\n",
        "    FROM exploded_elements\n",
        "    WHERE element_type = 'section_header'\n",
        "  ),\n",
        "  section_tracking AS (\n",
        "    SELECT\n",
        "      e.path,\n",
        "      e.element_id,\n",
        "      e.element_type,\n",
        "      e.element_content,\n",
        "      sh.mono_section_id AS section_id,\n",
        "      sh.element_content AS section_title\n",
        "    FROM exploded_elements e\n",
        "    LEFT JOIN LATERAL (\n",
        "      SELECT mono_section_id, element_content\n",
        "      FROM section_headers sh\n",
        "      WHERE sh.path = e.path AND sh.element_id::INT <= e.element_id::INT\n",
        "      ORDER BY sh.element_id::INT DESC\n",
        "      LIMIT 1\n",
        "    ) sh ON TRUE\n",
        "  )\n",
        "  SELECT\n",
        "    path,\n",
        "    section_id,\n",
        "    section_title,\n",
        "    CONCAT_WS('\\n', COLLECT_LIST(element_content)) AS text,\n",
        "    CONCAT_WS('\\n', section_title, COLLECT_LIST(element_content)) AS combined_text\n",
        "  FROM section_tracking\n",
        "  WHERE element_type = 'text' \n",
        "    AND section_id IS NOT NULL\n",
        "  GROUP BY path, section_id, section_title\n",
        ") AS source\n",
        "ON target.path = source.path AND target.section_id = source.section_id\n",
        "WHEN MATCHED THEN\n",
        "  UPDATE SET\n",
        "    section_title = source.section_title,\n",
        "    text = source.text,\n",
        "    combined_text = source.combined_text\n",
        "WHEN NOT MATCHED THEN\n",
        "  INSERT (path, section_id, section_title, text, combined_text)\n",
        "  VALUES (source.path, source.section_id, source.section_title, source.text, source.combined_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 3B: Set Up Vector Search\n",
        "\n",
        "This creates a Vector Search endpoint (if needed) and indexes three tables:\n",
        "- `flat` (indexed on preamble) -- for finding documents with similar openings\n",
        "- `doc_info` (indexed on combined_doc_info) -- for finding documents with similar metadata\n",
        "- `sections` (indexed on combined_text) -- for finding specific sections across documents\n",
        "\n",
        "If the indexes already exist, they will be synced instead of recreated."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create endpoint if it doesn't exist\n",
        "endpoints = [x['name'] for x in client.list_endpoints()['endpoints']]\n",
        "if not any(ep == endpoint_name for ep in endpoints):\n",
        "    client.create_endpoint(\n",
        "        name=endpoint_name,\n",
        "        endpoint_type=\"STANDARD\"\n",
        "    )\n",
        "\n",
        "# Enable change data feed on all source tables\n",
        "for tbl in tables.keys():\n",
        "    spark.sql(f\"\"\"\n",
        "        ALTER TABLE IDENTIFIER('{catalog}.{schema}.{tbl}') \n",
        "        SET TBLPROPERTIES (delta.enableChangeDataFeed = true)\n",
        "    \"\"\")\n",
        "\n",
        "# Create or sync vector search indexes\n",
        "for tbl in tables.keys():\n",
        "    try:\n",
        "        index = client.create_delta_sync_index(\n",
        "            endpoint_name=endpoint_name,\n",
        "            source_table_name=f\"{catalog}.{schema}.{tbl}\",\n",
        "            index_name=f\"{catalog}.{schema}.{tbl}_index\",\n",
        "            pipeline_type=\"TRIGGERED\",\n",
        "            primary_key=\"path\",\n",
        "            columns_to_sync=tables[tbl]['columns_to_sync'],\n",
        "            embedding_source_column=tables[tbl]['vs_col'],\n",
        "            embedding_model_endpoint_name=\"databricks-gte-large-en\",\n",
        "        )\n",
        "        print(f'Creating index for {tbl}')\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        index = client.get_index(index_name=f\"{catalog}.{schema}.{tbl}_index\")\n",
        "        index.sync()\n",
        "        print(f'Syncing index for {tbl}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test vector search\n",
        "\n",
        "Quick sanity check to make sure the indexes work."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "sql"
        }
      },
      "outputs": [],
      "source": [
        "SELECT * \n",
        "FROM vector_search(\n",
        "  index => :catalog || '.' || :schema || '.flat_index',\n",
        "  query_text => 'Contract No. 1885-16859 Amendment No. 1',\n",
        "  query_type => 'HYBRID',\n",
        "  num_results => 5\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 3C: Assemble Context\n",
        "\n",
        "This is the key step that brings everything together. For each contract, it assembles:\n",
        "\n",
        "- **doc_info** -- the contract's own extracted metadata\n",
        "- **preamble** -- the contract's first ~100 words\n",
        "- **vs_results** -- doc_info from the top 5 semantically similar documents (via vector search)\n",
        "- **vs_preamble_results** -- preambles from the top 5 semantically similar documents\n",
        "- **other_preambles / other_doc_infos** -- info from other documents in the same vendor folder\n",
        "\n",
        "The folder-level documents are especially important: amendments are almost always in the same folder as their master agreement."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "sql"
        }
      },
      "outputs": [],
      "source": [
        "CREATE TABLE IF NOT EXISTS IDENTIFIER(:catalog || '.' || :schema || '.assembled') (\n",
        "  path STRING,\n",
        "  doc_info STRING,\n",
        "  preamble STRING,\n",
        "  vs_results STRING,\n",
        "  vs_preamble_results STRING,\n",
        "  other_folder_docs BIGINT,\n",
        "  other_preambles STRING,\n",
        "  other_doc_infos STRING\n",
        ");\n",
        "\n",
        "MERGE INTO IDENTIFIER(:catalog || '.' || :schema || '.assembled') AS target\n",
        "USING (\n",
        "  WITH doc_info_search_results AS (\n",
        "    SELECT\n",
        "      doc.path,\n",
        "      concat_ws('\\n \\n ##### \\n \\n', collect_list(vs.combined_doc_info)) AS vs_combined_doc_info\n",
        "    FROM IDENTIFIER(:catalog || '.' || :schema || '.doc_info') doc\n",
        "    CROSS JOIN LATERAL (\n",
        "      SELECT combined_doc_info\n",
        "      FROM vector_search(\n",
        "        index => :catalog || '.' || :schema || '.doc_info_index',\n",
        "        query_text => substring(doc.combined_doc_info, 0, :vs_char_limit),\n",
        "        query_type => 'HYBRID',\n",
        "        num_results => 5\n",
        "      )\n",
        "    ) vs\n",
        "    GROUP BY doc.path\n",
        "  ),\n",
        "  preamble_search_results AS (\n",
        "    SELECT\n",
        "      f.path,\n",
        "      concat_ws('\\n \\n ##### \\n \\n', collect_list(vs_preamble.preamble)) AS vs_preamble_results\n",
        "    FROM IDENTIFIER(:catalog || '.' || :schema || '.flat') f\n",
        "    CROSS JOIN LATERAL (\n",
        "      SELECT preamble\n",
        "      FROM vector_search(\n",
        "        index => :catalog || '.' || :schema || '.flat_index',\n",
        "        query_text => substring(f.preamble, 0, :vs_char_limit),\n",
        "        query_type => 'HYBRID',\n",
        "        num_results => 5\n",
        "      )\n",
        "    ) vs_preamble\n",
        "    GROUP BY f.path\n",
        "  )\n",
        "  SELECT\n",
        "    base.path,\n",
        "    base.preamble,\n",
        "    doc.combined_doc_info AS doc_info,\n",
        "    vs.vs_combined_doc_info AS vs_results,\n",
        "    preamble_vs.vs_preamble_results AS vs_preamble_results,\n",
        "    count(DISTINCT rel.other_preamble) AS other_folder_docs,\n",
        "    concat_ws('\\n \\n ##### \\n \\n', collect_list(DISTINCT rel.other_preamble)) AS other_preambles,\n",
        "    concat_ws('\\n \\n ##### \\n \\n', collect_list(DISTINCT rel.other_combined_doc_info)) AS other_doc_infos\n",
        "  FROM IDENTIFIER(:catalog || '.' || :schema || '.flat') base\n",
        "  LEFT JOIN (\n",
        "    SELECT\n",
        "      o.other_path AS path,\n",
        "      t.preamble AS other_preamble,\n",
        "      doc.combined_doc_info AS other_combined_doc_info\n",
        "    FROM (\n",
        "      SELECT\n",
        "        path,\n",
        "        vendor_folder_path,\n",
        "        preamble\n",
        "      FROM IDENTIFIER(:catalog || '.' || :schema || '.flat')\n",
        "      LATERAL VIEW OUTER explode(vendor_folder_paths) AS vendor_folder_path\n",
        "    ) t\n",
        "    JOIN (\n",
        "      SELECT\n",
        "        path AS other_path,\n",
        "        vendor_folder_path AS other_vendor_folder_path\n",
        "      FROM IDENTIFIER(:catalog || '.' || :schema || '.flat')\n",
        "      LATERAL VIEW OUTER explode(vendor_folder_paths) AS vendor_folder_path\n",
        "    ) o\n",
        "      ON t.vendor_folder_path = o.other_vendor_folder_path\n",
        "      AND t.path <> o.other_path\n",
        "    LEFT JOIN IDENTIFIER(:catalog || '.' || :schema || '.doc_info') doc\n",
        "      ON t.path = doc.path\n",
        "  ) rel\n",
        "  ON base.path = rel.path\n",
        "  LEFT JOIN IDENTIFIER(:catalog || '.' || :schema || '.doc_info') doc\n",
        "  ON base.path = doc.path\n",
        "  LEFT JOIN doc_info_search_results vs\n",
        "  ON base.path = vs.path\n",
        "  LEFT JOIN preamble_search_results preamble_vs\n",
        "  ON base.path = preamble_vs.path\n",
        "  GROUP BY base.path, base.preamble, doc.combined_doc_info, vs.vs_combined_doc_info, preamble_vs.vs_preamble_results\n",
        ") AS source\n",
        "ON target.path = source.path\n",
        "WHEN NOT MATCHED THEN INSERT (\n",
        "  path,\n",
        "  doc_info,\n",
        "  preamble,\n",
        "  vs_results,\n",
        "  vs_preamble_results,\n",
        "  other_folder_docs,\n",
        "  other_preambles,\n",
        "  other_doc_infos\n",
        ") VALUES (\n",
        "  source.path,\n",
        "  source.doc_info,\n",
        "  source.preamble,\n",
        "  source.vs_results,\n",
        "  source.vs_preamble_results,\n",
        "  source.other_folder_docs,\n",
        "  source.other_preambles,\n",
        "  source.other_doc_infos\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "sql"
        }
      },
      "outputs": [],
      "source": [
        "-- Check: how many assembled records?\n",
        "SELECT COUNT(*) as total_assembled FROM IDENTIFIER(:catalog || '.' || :schema || '.assembled')"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
