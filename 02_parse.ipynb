{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "df51c214-8845-4efb-b44b-6d99d4f79da4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "This notebook uses small batches of parse_document to work through a large corpus of documents safely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "762062c4-0273-4c5f-8f58-d1cfcd4736ed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.widgets.text(\"catalog\", \"dev\", \"Catalog\")\n",
    "dbutils.widgets.text(\"schema\", \"raw\", \"Schema\")\n",
    "dbutils.widgets.text(\"batch_size\", \"100\", \"Batch Size\")\n",
    "catalog = dbutils.widgets.get(\"catalog\")\n",
    "schema = dbutils.widgets.get(\"schema\")\n",
    "batch_size = int(dbutils.widgets.get(\"batch_size\"))\n",
    "file_pattern = r'\\.(pdf|jpg|jpeg|png|doc|docx|ppt|pptx)$'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "332f10f4-90c4-458b-9e40-d60f8e957261",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.sql(f\"\"\"\n",
    "    SELECT \n",
    "        regexp_extract(file_name, r'\\\\.([a-zA-Z0-9]+)$', 1) AS file_extension,\n",
    "        COUNT(*) AS count\n",
    "    FROM {catalog}.{schema}.bytes\n",
    "    WHERE file_name RLIKE '{file_pattern}'\n",
    "    GROUP BY file_extension\n",
    "    ORDER BY count DESC\n",
    "\"\"\")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4ed34182-54db-4611-8da3-ccda9113cba1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Let's limit our files to pdfs only, since engineer suspects a bug with office files\n",
    "file_pattern = r'\\.(pdf|jpg|jpeg|png)$'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e7943f72-97a5-49e4-b9fc-aec4e1dbb725",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE TABLE IF NOT EXISTS IDENTIFIER(:catalog || '.' || :schema || '.parsed') (\n",
    "  path STRING NOT NULL PRIMARY KEY,\n",
    "  parsed VARIANT\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b908c410-6cd7-41ea-953d-bc940a49e349",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def remaining_count():\n",
    "    return spark.sql(f\"\"\"\n",
    "        SELECT COUNT(*) AS cnt\n",
    "        FROM {catalog}.{schema}.bytes AS b\n",
    "        LEFT JOIN {catalog}.{schema}.parsed AS p\n",
    "          ON b.path = p.path\n",
    "        WHERE b.file_name RLIKE '{file_pattern}'\n",
    "          AND p.path IS NULL\n",
    "    \"\"\").collect()[0][\"cnt\"]\n",
    "\n",
    "batch = 0\n",
    "start = time.time()\n",
    "\n",
    "while True:\n",
    "    remaining = remaining_count()\n",
    "    print(f\"Batch {batch+1}, remaining: {remaining}\")\n",
    "    if remaining == 0:\n",
    "        break\n",
    "\n",
    "    t0 = time.time()\n",
    "    spark.sql(f\"\"\"\n",
    "        MERGE INTO {catalog}.{schema}.parsed AS target\n",
    "        USING (\n",
    "          SELECT \n",
    "            b.path,\n",
    "            AI_PARSE_DOCUMENT(b.content) AS parsed\n",
    "          FROM (\n",
    "            SELECT b.path, content\n",
    "            FROM {catalog}.{schema}.bytes AS b\n",
    "            LEFT JOIN {catalog}.{schema}.parsed AS p\n",
    "              ON b.path = p.path\n",
    "            WHERE b.file_name RLIKE '{file_pattern}'\n",
    "              AND p.path IS NULL\n",
    "            ORDER BY b.length\n",
    "            LIMIT CAST({batch_size} AS INTEGER)\n",
    "          ) AS b\n",
    "        ) AS source\n",
    "        ON target.path = source.path\n",
    "        WHEN NOT MATCHED THEN INSERT *\n",
    "    \"\"\")\n",
    "    print(f\"Batch {batch} done in {time.time() - t0:.1f}s\")\n",
    "    batch += 1\n",
    "\n",
    "print(f\"All done in {time.time() - start:.1f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0ba933e8-f2b9-4484-b013-4832f1cc7b71",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT * \n",
    "FROM shm.contract.parsed\n",
    "WHERE length(concat_ws(\n",
    "        '\\n\\n',\n",
    "        transform(\n",
    "          try_cast(parsed:document:elements AS ARRAY<VARIANT>),\n",
    "          element -> try_cast(element:content AS STRING)\n",
    "        )\n",
    "      )) < 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7359e183-10ed-48fd-b717-94443f4b04d5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT * FROM shm.contract.parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4b5ef7f8-27bd-44b3-9b0d-4d09853b66ff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT * FROM shm.contract.parsed\n",
    "WHERE path ILIKE '%border%'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8d269677-5856-4bdb-8463-9aefd5941bf1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Deletes failed parsing runs\n",
    "DELETE FROM shm.contract.parsed\n",
    "WHERE length(concat_ws(\n",
    "        '\\n\\n',\n",
    "        transform(\n",
    "          try_cast(parsed:document:elements AS ARRAY<VARIANT>),\n",
    "          element -> try_cast(element:content AS STRING)\n",
    "        )\n",
    "      )) < 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ddc64bb3-852d-4758-a5da-f9274b168068",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Now let's focus on office files\n",
    "file_pattern = r'\\.(doc|docx|ppt|pptx)$'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "51fed7f7-6290-4491-87a1-499f64299417",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def remaining_count():\n",
    "    return spark.sql(f\"\"\"\n",
    "        SELECT COUNT(*) AS cnt\n",
    "        FROM {catalog}.{schema}.bytes AS b\n",
    "        LEFT JOIN {catalog}.{schema}.parsed AS p\n",
    "          ON b.path = p.path\n",
    "        WHERE b.file_name RLIKE '{file_pattern}'\n",
    "          AND p.path IS NULL\n",
    "    \"\"\").collect()[0][\"cnt\"]\n",
    "\n",
    "batch = 0\n",
    "start = time.time()\n",
    "\n",
    "while True:\n",
    "    remaining = remaining_count()\n",
    "    print(f\"Batch {batch+1}, remaining: {remaining}\")\n",
    "    if remaining == 0:\n",
    "        break\n",
    "\n",
    "    t0 = time.time()\n",
    "    spark.sql(f\"\"\"\n",
    "        MERGE INTO {catalog}.{schema}.parsed AS target\n",
    "        USING (\n",
    "          SELECT \n",
    "            b.path,\n",
    "            AI_PARSE_DOCUMENT(b.content) AS parsed\n",
    "          FROM (\n",
    "            SELECT path, content\n",
    "            FROM {catalog}.{schema}.bytes AS b\n",
    "            LEFT JOIN {catalog}.{schema}.parsed AS p\n",
    "              ON b.path = p.path\n",
    "            WHERE b.file_name RLIKE '{file_pattern}'\n",
    "              AND p.path IS NULL\n",
    "            ORDER BY b.length\n",
    "            LIMIT CAST({batch_size} AS INTEGER)\n",
    "          ) AS b\n",
    "        ) AS source\n",
    "        ON target.path = source.path\n",
    "        WHEN NOT MATCHED THEN INSERT *\n",
    "    \"\"\")\n",
    "    print(f\"Batch {batch} done in {time.time() - t0:.1f}s\")\n",
    "    batch += 1\n",
    "\n",
    "print(f\"All done in {time.time() - start:.1f}s\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 3582259051911545,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "02_parse",
   "widgets": {
    "batch_size": {
     "currentValue": "2",
     "nuid": "bb37e48f-ee5f-4910-9f0f-8a2f378e3a15",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "100",
      "label": "Batch Size",
      "name": "batch_size",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "100",
      "label": "Batch Size",
      "name": "batch_size",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "catalog": {
     "currentValue": "shm",
     "nuid": "81e00032-7083-462e-aaaf-9f94313c4744",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "dev",
      "label": "Catalog",
      "name": "catalog",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "dev",
      "label": "Catalog",
      "name": "catalog",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "schema": {
     "currentValue": "contract",
     "nuid": "0bcc4d4a-c9a9-4ab7-9fb5-e5634245a51b",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "raw",
      "label": "Schema",
      "name": "schema",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "raw",
      "label": "Schema",
      "name": "schema",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
